{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shearletNN.shearlets import getcomplexshearlets2D\n",
    "from shearletNN.shearlet_utils import frequency_shearlet_transform, spatial_shearlet_transform, ShearletTransformLoader\n",
    "from shearletNN.complex_resnet import complex_resnet18, complex_resnet34, complex_resnet50\n",
    "from shearletNN.layers import CGELU, CReLU\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import transforms\n",
    "\n",
    "import gc\n",
    "\n",
    "\n",
    "patch_size = 64\n",
    "image_size = 128\n",
    "\n",
    "rows, cols = image_size, image_size\n",
    "\n",
    "\n",
    "shearlets, shearletIdxs, RMS, dualFrameWeights = getcomplexshearlets2D(\trows, \n",
    "                                                                        cols, \n",
    "                                                                        1, \n",
    "                                                                        3, \n",
    "                                                                        1, \n",
    "                                                                        0.5,\n",
    "                                                                        wavelet_eff_support = image_size,\n",
    "                                                                        gaussian_eff_support = image_size\n",
    "                                                                        )\n",
    "\n",
    "shearlets = torch.tensor(shearlets).permute(2, 0, 1).type(torch.complex64).to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unraveling:\n",
    "    def __init__(self, n):\n",
    "        self.levels = []\n",
    "        for i in range(0, n // 2):\n",
    "            level = []\n",
    "            for j in range(i, n - i):\n",
    "                level.append((j, i))\n",
    "                level.append((i, j))\n",
    "\n",
    "                level.append((j, n - (i + 1)))\n",
    "                level.append((n - (i + 1), j))\n",
    "\n",
    "            level = list(set(level))\n",
    "            self.levels.append((torch.tensor([x for x, _ in level]), torch.tensor([y for _, y in level])))\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return [x[..., a, b] for a, b in self.levels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, optimizer, loader, accumulate=1):\n",
    "    model.train()\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for i, (X, y) in tqdm(enumerate(loader)):\n",
    "        out = model(X.to(0))\n",
    "        optimizer.zero_grad()\n",
    "        l = loss(out, y.to(0)) / accumulate\n",
    "        l.backward()\n",
    "        if i % accumulate == (accumulate - 1):\n",
    "            optimizer.step()\n",
    "        \n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    output = output.to(torch.device('cpu'))\n",
    "    target = target.to(torch.device('cpu'))\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.shape[0]\n",
    "\n",
    "    _, idx = output.sort(dim=1, descending=True)\n",
    "    pred = idx.narrow(1, 0, maxk).t()\n",
    "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(dim=0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "def epoch_accuracy(loader_s, student):\n",
    "    student.eval()\n",
    "\n",
    "    out_epoch_s = [accuracy(student(L.to(0)), y)[0].detach().cpu().item() for L, y in loader_s]\n",
    "\n",
    "    student.train()\n",
    "\n",
    "    return sum(out_epoch_s) / len(out_epoch_s)\n",
    "\n",
    "def test(network, test_loader):\n",
    "    network.eval().to(0)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_losses=[]\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data.to(0))\n",
    "            test_loss += torch.nn.CrossEntropyLoss()(output, target.to(0)).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1].cpu()\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "            total += target.shape[0]\n",
    "        test_loss /= total\n",
    "        test_losses.append(test_loss)\n",
    "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, total,\n",
    "        100. * correct / total))\n",
    "\n",
    "class IndexSubsetDataset:\n",
    "    def __init__(self, ds, inds):\n",
    "        self.ds = ds\n",
    "        self.inds = inds\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(len(self.inds)):\n",
    "            yield self[i]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.ds[self.inds[i]]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 30, 64, 64])\n",
      "torch.Size([64, 30, 252])\n"
     ]
    }
   ],
   "source": [
    "def repeat3(x):\n",
    "    return x.repeat(3, 1, 1)[:3]\n",
    "\n",
    "transform = v2.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    repeat3,\n",
    "])\n",
    "\n",
    "ds_train = torchvision.datasets.Caltech101('./', transform=transform, download = True)\n",
    "ds_train = IndexSubsetDataset(ds_train, sum([list(range(len(ds_train)))[i::5] for i in range(1, 5)], []))\n",
    "\n",
    "ds_val = torchvision.datasets.Caltech101('./', transform=transform, download = True)\n",
    "ds_val = IndexSubsetDataset(ds_val, list(range(len(ds_val)))[0::5])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  ds_train,\n",
    "  batch_size=batch_size_train, shuffle=True, num_workers=0)\n",
    "\n",
    "def shearlet_transform(img):\n",
    "    return frequency_shearlet_transform(img, shearlets, patch_size)\n",
    "\n",
    "train_loader = ShearletTransformLoader(train_loader, shearlet_transform)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "  ds_val,\n",
    "  batch_size=batch_size_train, shuffle=False)\n",
    "\n",
    "val_loader = ShearletTransformLoader(val_loader, shearlet_transform)\n",
    "\n",
    "for x, y in tqdm(train_loader):\n",
    "    assert list(x.shape) == [batch_size_train, shearlets.shape[0] * 3, patch_size, patch_size], x.shape\n",
    "    print(x.shape)\n",
    "    unravel = Unraveling(64)\n",
    "    print(unravel(x)[0].shape)\n",
    "    break\n",
    "\n",
    "for i, l in enumerate(unravel.levels[::-1]):\n",
    "    assert len(l[0]) == (i * 8) + 4, (i, len(l[0]), l)\n",
    "    for x, y in zip(*l):\n",
    "        if x != 31 - i and y != 31 - i:\n",
    "            if x != 32 + i and y != 32 + i:\n",
    "                assert False, (i, (x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnravelNN(torch.nn.Module):\n",
    "    def __init__(self, n, embed_dim):\n",
    "        sizes = [4 + i*8 for i in range(n)][::-1]\n",
    "        self.layers = torch.nn.ModuleList([torch.nn.Linear(size, embed_dim, dtype=torch.complex64) for size in sizes])\n",
    "        self.act = CReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.stack([layer(a) for layer, a in zip(self.layers, x)], -2) # (B, C, n, embed_dim)\n",
    "        # if we flatten the C and embed_dim together we have n tokens, one for each frequency level.  \n",
    "        # This is kind of what we would want as a transformer input\n",
    "        return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:03, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model...\n",
      "training model...\n",
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:35,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0672, Accuracy: 1217/6941 (18%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0695, Accuracy: 296/1736 (17%)\n",
      "\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:28,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0626, Accuracy: 1458/6941 (21%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0660, Accuracy: 352/1736 (20%)\n",
      "\n",
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:43,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0597, Accuracy: 1548/6941 (22%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0634, Accuracy: 354/1736 (20%)\n",
      "\n",
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:37,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0567, Accuracy: 1661/6941 (24%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0622, Accuracy: 385/1736 (22%)\n",
      "\n",
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:34,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0541, Accuracy: 1678/6941 (24%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0599, Accuracy: 368/1736 (21%)\n",
      "\n",
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:38,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0490, Accuracy: 2276/6941 (33%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0565, Accuracy: 485/1736 (28%)\n",
      "\n",
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:39,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0457, Accuracy: 2374/6941 (34%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0560, Accuracy: 516/1736 (30%)\n",
      "\n",
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:43,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0423, Accuracy: 2784/6941 (40%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0540, Accuracy: 529/1736 (30%)\n",
      "\n",
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:39,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0403, Accuracy: 3146/6941 (45%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0541, Accuracy: 534/1736 (31%)\n",
      "\n",
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:39,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0369, Accuracy: 3295/6941 (47%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0524, Accuracy: 550/1736 (32%)\n",
      "\n",
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:40,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0335, Accuracy: 3763/6941 (54%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0519, Accuracy: 559/1736 (32%)\n",
      "\n",
      "epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:41,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0314, Accuracy: 3835/6941 (55%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0523, Accuracy: 568/1736 (33%)\n",
      "\n",
      "epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:40,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0273, Accuracy: 4450/6941 (64%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0509, Accuracy: 570/1736 (33%)\n",
      "\n",
      "epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:39,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0238, Accuracy: 4895/6941 (71%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0505, Accuracy: 584/1736 (34%)\n",
      "\n",
      "epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:39,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0205, Accuracy: 5139/6941 (74%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0506, Accuracy: 589/1736 (34%)\n",
      "\n",
      "epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:40,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0182, Accuracy: 5483/6941 (79%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0507, Accuracy: 565/1736 (33%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def repeat3(x):\n",
    "    return x.repeat(3, 1, 1)[:3]\n",
    "\n",
    "transform = v2.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    repeat3,\n",
    "])\n",
    "\n",
    "ds_train = torchvision.datasets.Caltech101('./', transform=transform, download = True)\n",
    "ds_train = IndexSubsetDataset(ds_train, sum([list(range(len(ds_train)))[i::5] for i in range(1, 5)], []))\n",
    "\n",
    "ds_val = torchvision.datasets.Caltech101('./', transform=transform, download = True)\n",
    "ds_val = IndexSubsetDataset(ds_val, list(range(len(ds_val)))[0::5])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  ds_train,\n",
    "  batch_size=batch_size_train, shuffle=True, num_workers=0)\n",
    "\n",
    "def shearlet_transform(img):\n",
    "    return frequency_shearlet_transform(img, shearlets, patch_size)\n",
    "\n",
    "train_loader = ShearletTransformLoader(train_loader, shearlet_transform)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "  ds_val,\n",
    "  batch_size=batch_size_train, shuffle=False)\n",
    "\n",
    "val_loader = ShearletTransformLoader(val_loader, shearlet_transform)\n",
    "\n",
    "for x, y in tqdm(train_loader):\n",
    "    assert list(x.shape) == [batch_size_train, shearlets.shape[0] * 3, patch_size, patch_size], x.shape\n",
    "    break\n",
    "print('building model...')\n",
    "model = complex_resnet18(in_dim=shearlets.shape[0] * 3, complex=True, phasor=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "print('training model...')\n",
    "for epoch in range(16):\n",
    "    print('epoch', epoch)\n",
    "    train(model.to(0), optimizer, train_loader, accumulate=4)\n",
    "    gc.collect()\n",
    "    test(model, train_loader)\n",
    "    test(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaycr\\miniforge3\\envs\\shearlets\\lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "c:\\Users\\jaycr\\miniforge3\\envs\\shearlets\\lib\\site-packages\\timm\\models\\registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:04, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model...\n",
      "training model...\n",
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\jaycr\\shearlet-extraction\\shearlet-nn\\src\\shearletNN\\complex_deit.py:739: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaycr\\shearlet-extraction\\shearlet-nn\\src\\shearletNN\\complex_deit.py:790: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Copy.cpp:308.)\n",
      "  xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
      "0it [00:06, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "nan in fc1 output",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m16\u001b[39m):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch)\n\u001b[1;32m---> 43\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m     45\u001b[0m     test(model, train_loader)\n",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, loader, accumulate)\u001b[0m\n\u001b[0;32m      5\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (X, y) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(loader)):\n\u001b[1;32m----> 8\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     10\u001b[0m     l \u001b[38;5;241m=\u001b[39m loss(out, y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m0\u001b[39m)) \u001b[38;5;241m/\u001b[39m accumulate\n",
      "File \u001b[1;32mc:\\Users\\jaycr\\miniforge3\\envs\\shearlets\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jaycr\\miniforge3\\envs\\shearlets\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\shearlet-extraction\\shearlet-nn\\src\\shearletNN\\complex_deit.py:704\u001b[0m, in \u001b[0;36mvit_models.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 704\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_rate:\n\u001b[0;32m    707\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_rate), training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[1;32m~\\shearlet-extraction\\shearlet-nn\\src\\shearletNN\\complex_deit.py:942\u001b[0m, in \u001b[0;36mrope_vit_models.forward_features\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    940\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks):\n\u001b[0;32m    941\u001b[0m         \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m--> 942\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs_cis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreqs_cis\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    943\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39misnan()\u001b[38;5;241m.\u001b[39many(), i\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jaycr\\miniforge3\\envs\\shearlets\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jaycr\\miniforge3\\envs\\shearlets\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\shearlet-extraction\\shearlet-nn\\src\\shearletNN\\complex_deit.py:842\u001b[0m, in \u001b[0;36mRoPE_Layer_scale_init_Block.forward\u001b[1;34m(self, x, freqs_cis)\u001b[0m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, freqs_cis):\n\u001b[0;32m    839\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma_1 \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x), freqs_cis\u001b[38;5;241m=\u001b[39mfreqs_cis)\n\u001b[0;32m    841\u001b[0m     )\n\u001b[1;32m--> 842\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma_2 \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\jaycr\\miniforge3\\envs\\shearlets\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jaycr\\miniforge3\\envs\\shearlets\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\shearlet-extraction\\shearlet-nn\\src\\shearletNN\\complex_deit.py:269\u001b[0m, in \u001b[0;36mMlp.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    268\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)\n\u001b[1;32m--> 269\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39misnan()\u001b[38;5;241m.\u001b[39many(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnan in fc1 output\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    270\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(x)\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39misnan()\u001b[38;5;241m.\u001b[39many(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnan in act output\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: nan in fc1 output"
     ]
    }
   ],
   "source": [
    "from shearletNN.complex_deit import rope_mixed_ape_deit_small_patch8_LS, rope_mixed_ape_deit_small_patch16_LS\n",
    "from shearletNN.layers import CReLU\n",
    "\n",
    "def repeat3(x):\n",
    "    return x.repeat(3, 1, 1)[:3]\n",
    "\n",
    "transform = v2.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    repeat3,\n",
    "])\n",
    "\n",
    "ds_train = torchvision.datasets.Caltech101('./', transform=transform, download = True)\n",
    "ds_train = IndexSubsetDataset(ds_train, sum([list(range(len(ds_train)))[i::5] for i in range(1, 5)], []))\n",
    "\n",
    "ds_val = torchvision.datasets.Caltech101('./', transform=transform, download = True)\n",
    "ds_val = IndexSubsetDataset(ds_val, list(range(len(ds_val)))[0::5])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  ds_train,\n",
    "  batch_size=batch_size_train, shuffle=True, num_workers=0)\n",
    "\n",
    "def shearlet_transform(img):\n",
    "    return frequency_shearlet_transform(img, shearlets, patch_size)\n",
    "\n",
    "train_loader = ShearletTransformLoader(train_loader, shearlet_transform)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "  ds_val,\n",
    "  batch_size=batch_size_train, shuffle=False)\n",
    "\n",
    "val_loader = ShearletTransformLoader(val_loader, shearlet_transform)\n",
    "\n",
    "for x, y in tqdm(train_loader):\n",
    "    assert list(x.shape) == [batch_size_train, shearlets.shape[0] * 3, patch_size, patch_size], x.shape\n",
    "    break\n",
    "print('building model...')\n",
    "model = rope_mixed_ape_deit_small_patch16_LS(img_size=64, in_chans=shearlets.shape[0] * 3, act_layer=CGELU)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "print('training model...')\n",
    "for epoch in range(16):\n",
    "    print('epoch', epoch)\n",
    "    train(model.to(0), optimizer, train_loader, accumulate=4)\n",
    "    gc.collect()\n",
    "    test(model, train_loader)\n",
    "    test(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p\u001b[38;5;241m.\u001b[39misnan()\u001b[38;5;241m.\u001b[39many()\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    assert not p.isnan().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2.5989,   2.7786,  -1.9066,  ..., -16.6108, -14.2221, -14.1932],\n",
       "        [  5.6196,   4.4043,  -0.3138,  ..., -22.7475, -19.6062, -20.9539],\n",
       "        [  2.9905,   2.7827,  -3.0569,  ..., -16.7674, -13.6852, -11.4824],\n",
       "        ...,\n",
       "        [  7.8631,   6.3224,   0.2821,  ..., -23.9034, -23.6231, -24.1045],\n",
       "        [  3.3916,   2.9951,  -3.1254,  ..., -20.9101, -17.9030, -17.2719],\n",
       "        [  4.3800,   4.5667,   0.8396,  ..., -17.4205, -17.9941, -18.4154]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(5.4802, device='cuda:0'), tensor(0., device='cuda:0'))\n",
      "(tensor(1.5708, device='cuda:0'), tensor(-1.5708, device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "# amplitude:\n",
    "amp = torch.abs(x)\n",
    "print((amp.real.max(), amp.real.min()))\n",
    "\n",
    "phase = torch.arctan(x.imag / x.real)\n",
    "\n",
    "phase = torch.nan_to_num(torch.arctan(x.imag / x.real), posinf=torch.math.pi / 2, neginf= -torch.math.pi / 2)\n",
    "\n",
    "print((phase.real.max(), phase.real.min()))\n",
    "\n",
    "def to_magnitude_phase(x):\n",
    "    \"\"\"\n",
    "    return magnitude/phase representation \n",
    "    \"\"\"\n",
    "    return torch.complex(torch.abs(x), torch.nan_to_num(torch.arctan(x.imag / x.real), posinf=torch.math.pi / 2, neginf= -torch.math.pi / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1.5,.0,.0,.0]])\n",
    "layerNorm = torch.nn.LayerNorm(4, elementwise_affine = False)\n",
    "y1 = layerNorm(x)\n",
    "mean = x.mean(-1, keepdim = True)\n",
    "var = x.var(-1, keepdim = True, unbiased=False)\n",
    "y2 = (x-mean)/torch.sqrt(var+layerNorm.eps)\n",
    "\n",
    "torch.allclose(y1, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((50,20,100))\n",
    "\n",
    "layerNorm = torch.nn.LayerNorm(x.shape[-1], elementwise_affine = True)\n",
    "y1 = layerNorm(x)\n",
    "\n",
    "mean = torch.mean(x, dim=-1, keepdim=True)\n",
    "var = torch.square(x - mean).mean(dim=-1, keepdim=True)\n",
    "y2 = ((x - mean) / torch.sqrt(var + layerNorm.eps)) * layerNorm.weight + layerNorm.bias\n",
    "\n",
    "torch.allclose(y1, y2, atol=1e-5, rtol=1e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
