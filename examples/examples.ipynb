{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shearletNN.shearlets import getcomplexshearlets2D\n",
    "from shearletNN.shearlet_utils import frequency_shearlet_transform, spatial_shearlet_transform, ShearletTransformLoader\n",
    "from shearletNN.complex_resnet import complex_resnet18, complex_resnet34, complex_resnet50\n",
    "from shearletNN.layers import CGELU, CReLU\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import transforms\n",
    "\n",
    "import gc\n",
    "\n",
    "\n",
    "patch_size = 64\n",
    "image_size = 128\n",
    "\n",
    "rows, cols = image_size, image_size\n",
    "\n",
    "\n",
    "shearlets, shearletIdxs, RMS, dualFrameWeights = getcomplexshearlets2D(\trows, \n",
    "                                                                        cols, \n",
    "                                                                        1, \n",
    "                                                                        3, \n",
    "                                                                        1, \n",
    "                                                                        0.5,\n",
    "                                                                        wavelet_eff_support = image_size,\n",
    "                                                                        gaussian_eff_support = image_size\n",
    "                                                                        )\n",
    "\n",
    "shearlets = torch.tensor(shearlets).permute(2, 0, 1).type(torch.complex64).to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unraveling:\n",
    "    def __init__(self, n):\n",
    "        self.levels = []\n",
    "        for i in range(0, n // 2):\n",
    "            level = []\n",
    "            for j in range(i, n - i):\n",
    "                level.append((j, i))\n",
    "                level.append((i, j))\n",
    "\n",
    "                level.append((j, n - (i + 1)))\n",
    "                level.append((n - (i + 1), j))\n",
    "\n",
    "            level = list(set(level))\n",
    "            self.levels.append((torch.tensor([x for x, _ in level]), torch.tensor([y for _, y in level])))\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return [x[..., a, b] for a, b in self.levels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, optimizer, loader, accumulate=1):\n",
    "    model.train()\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for i, (X, y) in tqdm(enumerate(loader)):\n",
    "        out = model(X.to(0))\n",
    "        optimizer.zero_grad()\n",
    "        l = loss(out, y.to(0)) / accumulate\n",
    "        l.backward()\n",
    "        if i % accumulate == (accumulate - 1):\n",
    "            optimizer.step()\n",
    "        \n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    output = output.to(torch.device('cpu'))\n",
    "    target = target.to(torch.device('cpu'))\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.shape[0]\n",
    "\n",
    "    _, idx = output.sort(dim=1, descending=True)\n",
    "    pred = idx.narrow(1, 0, maxk).t()\n",
    "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(dim=0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "def epoch_accuracy(loader_s, student):\n",
    "    student.eval()\n",
    "\n",
    "    out_epoch_s = [accuracy(student(L.to(0)), y)[0].detach().cpu().item() for L, y in loader_s]\n",
    "\n",
    "    student.train()\n",
    "\n",
    "    return sum(out_epoch_s) / len(out_epoch_s)\n",
    "\n",
    "def test(network, test_loader):\n",
    "    network.eval().to(0)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_losses=[]\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data.to(0))\n",
    "            test_loss += torch.nn.CrossEntropyLoss()(output, target.to(0)).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1].cpu()\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "            total += target.shape[0]\n",
    "        test_loss /= total\n",
    "        test_losses.append(test_loss)\n",
    "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, total,\n",
    "        100. * correct / total))\n",
    "\n",
    "class IndexSubsetDataset:\n",
    "    def __init__(self, ds, inds):\n",
    "        self.ds = ds\n",
    "        self.inds = inds\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(len(self.inds)):\n",
    "            yield self[i]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.ds[self.inds[i]]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "building model...\n",
      "training model...\n",
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0168, Accuracy: 707/6941 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0169, Accuracy: 179/1736 (10%)\n",
      "\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0163, Accuracy: 693/6941 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0164, Accuracy: 174/1736 (10%)\n",
      "\n",
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0157, Accuracy: 1234/6941 (18%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0159, Accuracy: 295/1736 (17%)\n",
      "\n",
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0148, Accuracy: 1532/6941 (22%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0150, Accuracy: 378/1736 (22%)\n",
      "\n",
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0139, Accuracy: 1771/6941 (26%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0142, Accuracy: 439/1736 (25%)\n",
      "\n",
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:11,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0127, Accuracy: 2205/6941 (32%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0132, Accuracy: 546/1736 (31%)\n",
      "\n",
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0120, Accuracy: 2362/6941 (34%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0126, Accuracy: 563/1736 (32%)\n",
      "\n",
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0110, Accuracy: 2698/6941 (39%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0118, Accuracy: 636/1736 (37%)\n",
      "\n",
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:11,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0103, Accuracy: 2946/6941 (42%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0115, Accuracy: 649/1736 (37%)\n",
      "\n",
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0091, Accuracy: 3402/6941 (49%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0108, Accuracy: 700/1736 (40%)\n",
      "\n",
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0083, Accuracy: 3833/6941 (55%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0105, Accuracy: 742/1736 (43%)\n",
      "\n",
      "epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0074, Accuracy: 4099/6941 (59%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0101, Accuracy: 748/1736 (43%)\n",
      "\n",
      "epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:11,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0066, Accuracy: 4526/6941 (65%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0101, Accuracy: 772/1736 (44%)\n",
      "\n",
      "epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0058, Accuracy: 5046/6941 (73%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0099, Accuracy: 791/1736 (46%)\n",
      "\n",
      "epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:11,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0049, Accuracy: 5505/6941 (79%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0098, Accuracy: 805/1736 (46%)\n",
      "\n",
      "epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:11,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0039, Accuracy: 5855/6941 (84%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0096, Accuracy: 789/1736 (45%)\n",
      "\n",
      "epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0034, Accuracy: 6087/6941 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0099, Accuracy: 799/1736 (46%)\n",
      "\n",
      "epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0025, Accuracy: 6548/6941 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0097, Accuracy: 817/1736 (47%)\n",
      "\n",
      "epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0018, Accuracy: 6671/6941 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0096, Accuracy: 816/1736 (47%)\n",
      "\n",
      "epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:11,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0013, Accuracy: 6806/6941 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0098, Accuracy: 821/1736 (47%)\n",
      "\n",
      "epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0008, Accuracy: 6882/6941 (99%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0098, Accuracy: 816/1736 (47%)\n",
      "\n",
      "epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0005, Accuracy: 6915/6941 (100%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0099, Accuracy: 814/1736 (47%)\n",
      "\n",
      "epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 6925/6941 (100%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0099, Accuracy: 828/1736 (48%)\n",
      "\n",
      "epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 6927/6941 (100%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0099, Accuracy: 828/1736 (48%)\n",
      "\n",
      "epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 6932/6941 (100%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0099, Accuracy: 827/1736 (48%)\n",
      "\n",
      "epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 6932/6941 (100%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0101, Accuracy: 829/1736 (48%)\n",
      "\n",
      "epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 6934/6941 (100%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0100, Accuracy: 828/1736 (48%)\n",
      "\n",
      "epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 6931/6941 (100%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0102, Accuracy: 816/1736 (47%)\n",
      "\n",
      "epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 6932/6941 (100%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0102, Accuracy: 828/1736 (48%)\n",
      "\n",
      "epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 6936/6941 (100%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0102, Accuracy: 828/1736 (48%)\n",
      "\n",
      "epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 6936/6941 (100%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0102, Accuracy: 838/1736 (48%)\n",
      "\n",
      "epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:10,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 6935/6941 (100%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0103, Accuracy: 828/1736 (48%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from shearletNN.deit import deit_small_patch16_LS\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "def repeat3(x):\n",
    "    return x.repeat(3, 1, 1)[:3]\n",
    "\n",
    "transform = v2.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    repeat3,\n",
    "])\n",
    "\n",
    "ds_train = torchvision.datasets.Caltech101('./', transform=transform, download = True)\n",
    "ds_train = IndexSubsetDataset(ds_train, sum([list(range(len(ds_train)))[i::5] for i in range(1, 5)], []))\n",
    "\n",
    "ds_val = torchvision.datasets.Caltech101('./', transform=transform, download = True)\n",
    "ds_val = IndexSubsetDataset(ds_val, list(range(len(ds_val)))[0::5])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  ds_train,\n",
    "  batch_size=batch_size_train, shuffle=True, num_workers=0)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "  ds_val,\n",
    "  batch_size=batch_size_train, shuffle=False)\n",
    "\n",
    "for x, y in tqdm(train_loader):\n",
    "    print(x.dtype)\n",
    "    assert list(x.shape) == [batch_size_train, 3, image_size, image_size], x.shape\n",
    "    break\n",
    "print('building model...')\n",
    "model = deit_small_patch16_LS(img_size=128, in_chans=3, num_classes=101)\n",
    "\n",
    "for p in model.parameters():\n",
    "    assert not p.isnan().any()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "print('training model...')\n",
    "for epoch in range(32):\n",
    "    print('epoch', epoch)\n",
    "    train(model.to(0), optimizer, train_loader, accumulate=1)\n",
    "    gc.collect()\n",
    "    test(model, train_loader)\n",
    "    test(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "torch.Size([64, 30, 128, 128])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m ShearletTransformLoader(val_loader, shearlet_transform)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader):\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m [batch_size_train, \u001b[38;5;241m6\u001b[39m, patch_size, patch_size], x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuilding model...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: torch.Size([64, 30, 128, 128])"
     ]
    }
   ],
   "source": [
    "def repeat3(x):\n",
    "    return x.repeat(3, 1, 1)[:3]\n",
    "\n",
    "transform = v2.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    repeat3,\n",
    "])\n",
    "\n",
    "ds_train = torchvision.datasets.Caltech101('./', transform=transform, download = True)\n",
    "ds_train = IndexSubsetDataset(ds_train, sum([list(range(len(ds_train)))[i::5] for i in range(1, 5)], []))\n",
    "\n",
    "ds_val = torchvision.datasets.Caltech101('./', transform=transform, download = True)\n",
    "ds_val = IndexSubsetDataset(ds_val, list(range(len(ds_val)))[0::5])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  ds_train,\n",
    "  batch_size=batch_size_train, shuffle=True, num_workers=0)\n",
    "\n",
    "def shearlet_transform(img):\n",
    "    return frequency_shearlet_transform(img, shearlets, patch_size)\n",
    "\n",
    "train_loader = ShearletTransformLoader(train_loader, shearlet_transform)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "  ds_val,\n",
    "  batch_size=batch_size_train, shuffle=False)\n",
    "\n",
    "val_loader = ShearletTransformLoader(val_loader, shearlet_transform)\n",
    "\n",
    "for x, y in tqdm(train_loader):\n",
    "    assert list(x.shape) == [batch_size_train, 6, patch_size, patch_size], x.shape\n",
    "    break\n",
    "print('building model...')\n",
    "model = complex_resnet18(in_dim=6, complex=True, phasor=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "print('training model...')\n",
    "for epoch in range(16):\n",
    "    print('epoch', epoch)\n",
    "    train(model.to(0), optimizer, train_loader, accumulate=1)\n",
    "    gc.collect()\n",
    "    test(model, train_loader)\n",
    "    test(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnravelNN(torch.nn.Module):\n",
    "    def __init__(self, n, embed_dim):\n",
    "        sizes = [4 + i*8 for i in range(n)][::-1]\n",
    "        self.layers = torch.nn.ModuleList([torch.nn.Linear(size, embed_dim, dtype=torch.complex64) for size in sizes])\n",
    "        self.act = CReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.stack([layer(a) for layer, a in zip(self.layers, x)], -2) # (B, C, n, embed_dim)\n",
    "        # if we flatten the C and embed_dim together we have n tokens, one for each frequency level.  \n",
    "        # This is kind of what we would want as a transformer input\n",
    "        return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:03, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model...\n",
      "training model...\n",
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/jroth/shearlet-extraction/shearlet-nn/src/shearletNN/complex_deit.py:738: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/home/jroth/shearlet-extraction/shearlet-nn/src/shearletNN/complex_deit.py:789: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/native/Copy.cpp:305.)\n",
      "  xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
      "109it [00:25,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0722, Accuracy: 638/6941 (9%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0742, Accuracy: 160/1736 (9%)\n",
      "\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:24,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0711, Accuracy: 764/6941 (11%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0731, Accuracy: 199/1736 (11%)\n",
      "\n",
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:24,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0651, Accuracy: 756/6941 (11%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0682, Accuracy: 199/1736 (11%)\n",
      "\n",
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:24,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0644, Accuracy: 860/6941 (12%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0671, Accuracy: 212/1736 (12%)\n",
      "\n",
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:23,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0641, Accuracy: 836/6941 (12%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0667, Accuracy: 208/1736 (12%)\n",
      "\n",
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:25,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0637, Accuracy: 849/6941 (12%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0670, Accuracy: 208/1736 (12%)\n",
      "\n",
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:24,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0633, Accuracy: 924/6941 (13%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0670, Accuracy: 228/1736 (13%)\n",
      "\n",
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:24,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0626, Accuracy: 974/6941 (14%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0662, Accuracy: 237/1736 (14%)\n",
      "\n",
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:23,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0620, Accuracy: 1099/6941 (16%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0661, Accuracy: 265/1736 (15%)\n",
      "\n",
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:24,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0613, Accuracy: 1161/6941 (17%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0663, Accuracy: 278/1736 (16%)\n",
      "\n",
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:23,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0606, Accuracy: 1216/6941 (18%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0657, Accuracy: 289/1736 (17%)\n",
      "\n",
      "epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:23,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0598, Accuracy: 1218/6941 (18%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0646, Accuracy: 286/1736 (16%)\n",
      "\n",
      "epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:23,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0595, Accuracy: 1243/6941 (18%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0649, Accuracy: 296/1736 (17%)\n",
      "\n",
      "epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:23,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0584, Accuracy: 1297/6941 (19%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0643, Accuracy: 299/1736 (17%)\n",
      "\n",
      "epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:24,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0581, Accuracy: 1382/6941 (20%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0640, Accuracy: 329/1736 (19%)\n",
      "\n",
      "epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:24,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0575, Accuracy: 1402/6941 (20%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0647, Accuracy: 330/1736 (19%)\n",
      "\n",
      "epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:24,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0567, Accuracy: 1430/6941 (21%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0634, Accuracy: 327/1736 (19%)\n",
      "\n",
      "epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:25,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0559, Accuracy: 1495/6941 (22%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0632, Accuracy: 335/1736 (19%)\n",
      "\n",
      "epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:25,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0558, Accuracy: 1537/6941 (22%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0625, Accuracy: 356/1736 (21%)\n",
      "\n",
      "epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:24,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0552, Accuracy: 1547/6941 (22%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0626, Accuracy: 334/1736 (19%)\n",
      "\n",
      "epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:24,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0547, Accuracy: 1624/6941 (23%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0619, Accuracy: 352/1736 (20%)\n",
      "\n",
      "epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:24,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0544, Accuracy: 1679/6941 (24%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0623, Accuracy: 354/1736 (20%)\n",
      "\n",
      "epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:24,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0543, Accuracy: 1668/6941 (24%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0618, Accuracy: 354/1736 (20%)\n",
      "\n",
      "epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:24,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0538, Accuracy: 1697/6941 (24%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0618, Accuracy: 369/1736 (21%)\n",
      "\n",
      "epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:25,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0534, Accuracy: 1729/6941 (25%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0619, Accuracy: 355/1736 (20%)\n",
      "\n",
      "epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:24,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0529, Accuracy: 1780/6941 (26%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0621, Accuracy: 378/1736 (22%)\n",
      "\n",
      "epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:23,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0531, Accuracy: 1738/6941 (25%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0620, Accuracy: 362/1736 (21%)\n",
      "\n",
      "epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:23,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0527, Accuracy: 1829/6941 (26%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0613, Accuracy: 376/1736 (22%)\n",
      "\n",
      "epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:24,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0526, Accuracy: 1806/6941 (26%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0615, Accuracy: 368/1736 (21%)\n",
      "\n",
      "epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:24,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0522, Accuracy: 1809/6941 (26%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0617, Accuracy: 383/1736 (22%)\n",
      "\n",
      "epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:23,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0517, Accuracy: 1855/6941 (27%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0616, Accuracy: 374/1736 (22%)\n",
      "\n",
      "epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:24,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0520, Accuracy: 1823/6941 (26%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0619, Accuracy: 384/1736 (22%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from shearletNN.complex_deit import complex_rope_mixed_deit_small_patch16_LS\n",
    "from shearletNN.layers import CGELU\n",
    "\n",
    "def repeat3(x):\n",
    "    return x.repeat(3, 1, 1)[:3]\n",
    "\n",
    "transform = v2.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    repeat3,\n",
    "])\n",
    "\n",
    "ds_train = torchvision.datasets.Caltech101('./', transform=transform, download = True)\n",
    "ds_train = IndexSubsetDataset(ds_train, sum([list(range(len(ds_train)))[i::5] for i in range(1, 5)], []))\n",
    "\n",
    "ds_val = torchvision.datasets.Caltech101('./', transform=transform, download = True)\n",
    "ds_val = IndexSubsetDataset(ds_val, list(range(len(ds_val)))[0::5])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  ds_train,\n",
    "  batch_size=batch_size_train, shuffle=True, num_workers=0)\n",
    "\n",
    "def shearlet_transform(img):\n",
    "    return frequency_shearlet_transform(img, shearlets, patch_size)\n",
    "\n",
    "train_loader = ShearletTransformLoader(train_loader, shearlet_transform)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "  ds_val,\n",
    "  batch_size=batch_size_train, shuffle=False)\n",
    "\n",
    "val_loader = ShearletTransformLoader(val_loader, shearlet_transform)\n",
    "\n",
    "for x, y in tqdm(train_loader):\n",
    "    assert list(x.shape) == [batch_size_train, 3 * shearlets.shape[0], patch_size, patch_size], x.shape\n",
    "    break\n",
    "print('building model...')\n",
    "model = complex_rope_mixed_deit_small_patch16_LS(img_size=patch_size, in_chans=3 * shearlets.shape[0], act_layer=CGELU, num_classes=101)\n",
    "for p in model.parameters():\n",
    "    assert not p.isnan().any()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "print('training model...')\n",
    "for epoch in range(32):\n",
    "    print('epoch', epoch)\n",
    "    train(model.to(0), optimizer, train_loader, accumulate=4)\n",
    "    gc.collect()\n",
    "    test(model, train_loader)\n",
    "    test(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaycr\\miniforge3\\envs\\shearlets\\lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "c:\\Users\\jaycr\\miniforge3\\envs\\shearlets\\lib\\site-packages\\timm\\models\\registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:04, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model...\n",
      "training model...\n",
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\jaycr\\shearlet-extraction\\shearlet-nn\\src\\shearletNN\\complex_deit.py:739: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaycr\\shearlet-extraction\\shearlet-nn\\src\\shearletNN\\complex_deit.py:790: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Copy.cpp:308.)\n",
      "  xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
      "0it [00:06, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "nan in fc1 output",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m16\u001b[39m):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch)\n\u001b[1;32m---> 43\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m     45\u001b[0m     test(model, train_loader)\n",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, loader, accumulate)\u001b[0m\n\u001b[0;32m      5\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (X, y) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(loader)):\n\u001b[1;32m----> 8\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     10\u001b[0m     l \u001b[38;5;241m=\u001b[39m loss(out, y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m0\u001b[39m)) \u001b[38;5;241m/\u001b[39m accumulate\n",
      "File \u001b[1;32mc:\\Users\\jaycr\\miniforge3\\envs\\shearlets\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jaycr\\miniforge3\\envs\\shearlets\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\shearlet-extraction\\shearlet-nn\\src\\shearletNN\\complex_deit.py:704\u001b[0m, in \u001b[0;36mvit_models.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 704\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_rate:\n\u001b[0;32m    707\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_rate), training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[1;32m~\\shearlet-extraction\\shearlet-nn\\src\\shearletNN\\complex_deit.py:942\u001b[0m, in \u001b[0;36mrope_vit_models.forward_features\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    940\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks):\n\u001b[0;32m    941\u001b[0m         \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m--> 942\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs_cis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreqs_cis\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    943\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39misnan()\u001b[38;5;241m.\u001b[39many(), i\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jaycr\\miniforge3\\envs\\shearlets\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jaycr\\miniforge3\\envs\\shearlets\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\shearlet-extraction\\shearlet-nn\\src\\shearletNN\\complex_deit.py:842\u001b[0m, in \u001b[0;36mRoPE_Layer_scale_init_Block.forward\u001b[1;34m(self, x, freqs_cis)\u001b[0m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, freqs_cis):\n\u001b[0;32m    839\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma_1 \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x), freqs_cis\u001b[38;5;241m=\u001b[39mfreqs_cis)\n\u001b[0;32m    841\u001b[0m     )\n\u001b[1;32m--> 842\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma_2 \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\jaycr\\miniforge3\\envs\\shearlets\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jaycr\\miniforge3\\envs\\shearlets\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\shearlet-extraction\\shearlet-nn\\src\\shearletNN\\complex_deit.py:269\u001b[0m, in \u001b[0;36mMlp.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    268\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)\n\u001b[1;32m--> 269\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39misnan()\u001b[38;5;241m.\u001b[39many(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnan in fc1 output\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    270\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(x)\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39misnan()\u001b[38;5;241m.\u001b[39many(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnan in act output\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: nan in fc1 output"
     ]
    }
   ],
   "source": [
    "from shearletNN.complex_deit import rope_mixed_ape_deit_small_patch8_LS, rope_mixed_ape_deit_small_patch16_LS\n",
    "from shearletNN.layers import CReLU\n",
    "\n",
    "def repeat3(x):\n",
    "    return x.repeat(3, 1, 1)[:3]\n",
    "\n",
    "transform = v2.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    repeat3,\n",
    "])\n",
    "\n",
    "ds_train = torchvision.datasets.Caltech101('./', transform=transform, download = True)\n",
    "ds_train = IndexSubsetDataset(ds_train, sum([list(range(len(ds_train)))[i::5] for i in range(1, 5)], []))\n",
    "\n",
    "ds_val = torchvision.datasets.Caltech101('./', transform=transform, download = True)\n",
    "ds_val = IndexSubsetDataset(ds_val, list(range(len(ds_val)))[0::5])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  ds_train,\n",
    "  batch_size=batch_size_train, shuffle=True, num_workers=0)\n",
    "\n",
    "def shearlet_transform(img):\n",
    "    return frequency_shearlet_transform(img, shearlets, patch_size)\n",
    "\n",
    "train_loader = ShearletTransformLoader(train_loader, shearlet_transform)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "  ds_val,\n",
    "  batch_size=batch_size_train, shuffle=False)\n",
    "\n",
    "val_loader = ShearletTransformLoader(val_loader, shearlet_transform)\n",
    "\n",
    "for x, y in tqdm(train_loader):\n",
    "    assert list(x.shape) == [batch_size_train, shearlets.shape[0] * 3, patch_size, patch_size], x.shape\n",
    "    break\n",
    "print('building model...')\n",
    "model = rope_mixed_ape_deit_small_patch16_LS(img_size=64, in_chans=shearlets.shape[0] * 3, act_layer=CGELU)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "print('training model...')\n",
    "for epoch in range(16):\n",
    "    print('epoch', epoch)\n",
    "    train(model.to(0), optimizer, train_loader, accumulate=4)\n",
    "    gc.collect()\n",
    "    test(model, train_loader)\n",
    "    test(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p\u001b[38;5;241m.\u001b[39misnan()\u001b[38;5;241m.\u001b[39many()\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    assert not p.isnan().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2.5989,   2.7786,  -1.9066,  ..., -16.6108, -14.2221, -14.1932],\n",
       "        [  5.6196,   4.4043,  -0.3138,  ..., -22.7475, -19.6062, -20.9539],\n",
       "        [  2.9905,   2.7827,  -3.0569,  ..., -16.7674, -13.6852, -11.4824],\n",
       "        ...,\n",
       "        [  7.8631,   6.3224,   0.2821,  ..., -23.9034, -23.6231, -24.1045],\n",
       "        [  3.3916,   2.9951,  -3.1254,  ..., -20.9101, -17.9030, -17.2719],\n",
       "        [  4.3800,   4.5667,   0.8396,  ..., -17.4205, -17.9941, -18.4154]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(5.4802, device='cuda:0'), tensor(0., device='cuda:0'))\n",
      "(tensor(1.5708, device='cuda:0'), tensor(-1.5708, device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "# amplitude:\n",
    "amp = torch.abs(x)\n",
    "print((amp.real.max(), amp.real.min()))\n",
    "\n",
    "phase = torch.arctan(x.imag / x.real)\n",
    "\n",
    "phase = torch.nan_to_num(torch.arctan(x.imag / x.real), posinf=torch.math.pi / 2, neginf= -torch.math.pi / 2)\n",
    "\n",
    "print((phase.real.max(), phase.real.min()))\n",
    "\n",
    "def to_magnitude_phase(x):\n",
    "    \"\"\"\n",
    "    return magnitude/phase representation \n",
    "    \"\"\"\n",
    "    return torch.complex(torch.abs(x), torch.nan_to_num(torch.arctan(x.imag / x.real), posinf=torch.math.pi / 2, neginf= -torch.math.pi / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1.5,.0,.0,.0]])\n",
    "layerNorm = torch.nn.LayerNorm(4, elementwise_affine = False)\n",
    "y1 = layerNorm(x)\n",
    "mean = x.mean(-1, keepdim = True)\n",
    "var = x.var(-1, keepdim = True, unbiased=False)\n",
    "y2 = (x-mean)/torch.sqrt(var+layerNorm.eps)\n",
    "\n",
    "torch.allclose(y1, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((50,20,100))\n",
    "\n",
    "layerNorm = torch.nn.LayerNorm(x.shape[-1], elementwise_affine = True)\n",
    "y1 = layerNorm(x)\n",
    "\n",
    "mean = torch.mean(x, dim=-1, keepdim=True)\n",
    "var = torch.square(x - mean).mean(dim=-1, keepdim=True)\n",
    "y2 = ((x - mean) / torch.sqrt(var + layerNorm.eps)) * layerNorm.weight + layerNorm.bias\n",
    "\n",
    "torch.allclose(y1, y2, atol=1e-5, rtol=1e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
