{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shearletNN.shearlets import getcomplexshearlets2D\n",
    "from shearletNN.shearlet_utils import frequency_shearlet_transform, spatial_shearlet_transform, ShearletTransformLoader\n",
    "from shearletNN.complex_resnet import complex_resnet18, complex_resnet34, complex_resnet50\n",
    "from shearletNN.layers import CGELU\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import transforms\n",
    "\n",
    "import gc\n",
    "\n",
    "\n",
    "patch_size = 64\n",
    "image_size = 128\n",
    "\n",
    "rows, cols = image_size, image_size\n",
    "\n",
    "\n",
    "shearlets, shearletIdxs, RMS, dualFrameWeights = getcomplexshearlets2D(\trows, \n",
    "                                                                        cols, \n",
    "                                                                        1, \n",
    "                                                                        3, \n",
    "                                                                        1, \n",
    "                                                                        0.5,\n",
    "                                                                        wavelet_eff_support = image_size,\n",
    "                                                                        gaussian_eff_support = image_size\n",
    "                                                                        )\n",
    "\n",
    "shearlets = torch.tensor(shearlets).permute(2, 0, 1).type(torch.complex64).to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, optimizer, loader, accumulate=1):\n",
    "    model.train()\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for i, (X, y) in tqdm(enumerate(loader)):\n",
    "        out = model(X.to(0))\n",
    "        optimizer.zero_grad()\n",
    "        l = loss(out, y.to(0)) / accumulate\n",
    "        l.backward()\n",
    "        if i % accumulate == (accumulate - 1):\n",
    "            optimizer.step()\n",
    "        \n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    output = output.to(torch.device('cpu'))\n",
    "    target = target.to(torch.device('cpu'))\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.shape[0]\n",
    "\n",
    "    _, idx = output.sort(dim=1, descending=True)\n",
    "    pred = idx.narrow(1, 0, maxk).t()\n",
    "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(dim=0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "def epoch_accuracy(loader_s, student):\n",
    "    student.eval()\n",
    "\n",
    "    out_epoch_s = [accuracy(student(L.to(0)), y)[0].detach().cpu().item() for L, y in loader_s]\n",
    "\n",
    "    student.train()\n",
    "\n",
    "    return sum(out_epoch_s) / len(out_epoch_s)\n",
    "\n",
    "def test(network, test_loader):\n",
    "    network.eval().to(0)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_losses=[]\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data.to(0))\n",
    "            test_loss += torch.nn.CrossEntropyLoss()(output, target.to(0)).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1].cpu()\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "            total += target.shape[0]\n",
    "        test_loss /= total\n",
    "        test_losses.append(test_loss)\n",
    "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, total,\n",
    "        100. * correct / total))\n",
    "\n",
    "class IndexSubsetDataset:\n",
    "    def __init__(self, ds, inds):\n",
    "        self.ds = ds\n",
    "        self.inds = inds\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(len(self.inds)):\n",
    "            yield self[i]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.ds[self.inds[i]]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaycr\\miniforge3\\envs\\shearlets\\lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "c:\\Users\\jaycr\\miniforge3\\envs\\shearlets\\lib\\site-packages\\timm\\models\\registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model...\n",
      "training model...\n",
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\jaycr\\shearlet-extraction\\shearlet-nn\\src\\shearletNN\\complex_deit.py:732: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "C:\\Users\\jaycr\\shearlet-extraction\\shearlet-nn\\src\\shearletNN\\complex_deit.py:783: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Copy.cpp:308.)\n",
      "  xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
      "0it [00:02, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m16\u001b[39m):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch)\n\u001b[1;32m---> 43\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m     45\u001b[0m     test(model, train_loader)\n",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, loader, accumulate)\u001b[0m\n\u001b[0;32m      5\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (X, y) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(loader)):\n\u001b[1;32m----> 8\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     10\u001b[0m     l \u001b[38;5;241m=\u001b[39m loss(out, y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m0\u001b[39m)) \u001b[38;5;241m/\u001b[39m accumulate\n",
      "File \u001b[1;32mc:\\Users\\jaycr\\miniforge3\\envs\\shearlets\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jaycr\\miniforge3\\envs\\shearlets\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\shearlet-extraction\\shearlet-nn\\src\\shearletNN\\complex_deit.py:697\u001b[0m, in \u001b[0;36mvit_models.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 697\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_rate:\n\u001b[0;32m    700\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_rate), training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[1;32m~\\shearlet-extraction\\shearlet-nn\\src\\shearletNN\\complex_deit.py:931\u001b[0m, in \u001b[0;36mrope_vit_models.forward_features\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    928\u001b[0m     freqs_cis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_cis(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreqs, t_x, t_y)\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks):\n\u001b[1;32m--> 931\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39misnan()\u001b[38;5;241m.\u001b[39many(), i\n\u001b[0;32m    932\u001b[0m         x \u001b[38;5;241m=\u001b[39m blk(x, freqs_cis\u001b[38;5;241m=\u001b[39mfreqs_cis[i])\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mAssertionError\u001b[0m: 10"
     ]
    }
   ],
   "source": [
    "from shearletNN.complex_deit import rope_mixed_ape_deit_small_patch8_LS, rope_mixed_ape_deit_small_patch16_LS\n",
    "from shearletNN.layers import CReLU\n",
    "\n",
    "def repeat3(x):\n",
    "    return x.repeat(3, 1, 1)[:3]\n",
    "\n",
    "transform = v2.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    repeat3,\n",
    "])\n",
    "\n",
    "ds_train = torchvision.datasets.Caltech101('./', transform=transform, download = True)\n",
    "ds_train = IndexSubsetDataset(ds_train, sum([list(range(len(ds_train)))[i::5] for i in range(1, 5)], []))\n",
    "\n",
    "ds_val = torchvision.datasets.Caltech101('./', transform=transform, download = True)\n",
    "ds_val = IndexSubsetDataset(ds_val, list(range(len(ds_val)))[0::5])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  ds_train,\n",
    "  batch_size=batch_size_train, shuffle=True, num_workers=0)\n",
    "\n",
    "def shearlet_transform(img):\n",
    "    return frequency_shearlet_transform(img, shearlets, patch_size)\n",
    "\n",
    "train_loader = ShearletTransformLoader(train_loader, shearlet_transform)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "  ds_val,\n",
    "  batch_size=batch_size_train, shuffle=False)\n",
    "\n",
    "val_loader = ShearletTransformLoader(val_loader, shearlet_transform)\n",
    "\n",
    "for x, y in tqdm(train_loader):\n",
    "    assert list(x.shape) == [batch_size_train, shearlets.shape[0] * 3, patch_size, patch_size], x.shape\n",
    "    break\n",
    "print('building model...')\n",
    "model = rope_mixed_ape_deit_small_patch16_LS(img_size=64, in_chans=shearlets.shape[0] * 3, act_layer=CGELU)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "print('training model...')\n",
    "for epoch in range(16):\n",
    "    print('epoch', epoch)\n",
    "    train(model.to(0), optimizer, train_loader, accumulate=4)\n",
    "    gc.collect()\n",
    "    test(model, train_loader)\n",
    "    test(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2.5989,   2.7786,  -1.9066,  ..., -16.6108, -14.2221, -14.1932],\n",
       "        [  5.6196,   4.4043,  -0.3138,  ..., -22.7475, -19.6062, -20.9539],\n",
       "        [  2.9905,   2.7827,  -3.0569,  ..., -16.7674, -13.6852, -11.4824],\n",
       "        ...,\n",
       "        [  7.8631,   6.3224,   0.2821,  ..., -23.9034, -23.6231, -24.1045],\n",
       "        [  3.3916,   2.9951,  -3.1254,  ..., -20.9101, -17.9030, -17.2719],\n",
       "        [  4.3800,   4.5667,   0.8396,  ..., -17.4205, -17.9941, -18.4154]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model...\n",
      "training model...\n",
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:34,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0667, Accuracy: 718/6941 (10%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0690, Accuracy: 184/1736 (11%)\n",
      "\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:33,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0617, Accuracy: 1468/6941 (21%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0652, Accuracy: 359/1736 (21%)\n",
      "\n",
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:33,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0578, Accuracy: 1570/6941 (23%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0627, Accuracy: 369/1736 (21%)\n",
      "\n",
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:33,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0526, Accuracy: 1973/6941 (28%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0593, Accuracy: 444/1736 (26%)\n",
      "\n",
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:34,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0484, Accuracy: 2275/6941 (33%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0562, Accuracy: 509/1736 (29%)\n",
      "\n",
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:33,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0459, Accuracy: 2535/6941 (37%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0553, Accuracy: 491/1736 (28%)\n",
      "\n",
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:33,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0406, Accuracy: 3207/6941 (46%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0518, Accuracy: 553/1736 (32%)\n",
      "\n",
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:33,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0373, Accuracy: 3300/6941 (48%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0516, Accuracy: 577/1736 (33%)\n",
      "\n",
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:33,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0346, Accuracy: 3563/6941 (51%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0508, Accuracy: 568/1736 (33%)\n",
      "\n",
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:33,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0311, Accuracy: 3961/6941 (57%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0497, Accuracy: 602/1736 (35%)\n",
      "\n",
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:33,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0268, Accuracy: 4605/6941 (66%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0498, Accuracy: 612/1736 (35%)\n",
      "\n",
      "epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:33,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0242, Accuracy: 4916/6941 (71%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0483, Accuracy: 611/1736 (35%)\n",
      "\n",
      "epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:33,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0204, Accuracy: 5310/6941 (77%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0478, Accuracy: 630/1736 (36%)\n",
      "\n",
      "epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:33,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0173, Accuracy: 5544/6941 (80%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0473, Accuracy: 638/1736 (37%)\n",
      "\n",
      "epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:33,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0156, Accuracy: 5723/6941 (82%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0478, Accuracy: 618/1736 (36%)\n",
      "\n",
      "epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:33,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0130, Accuracy: 5916/6941 (85%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0481, Accuracy: 632/1736 (36%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def repeat3(x):\n",
    "    return x.repeat(3, 1, 1)[:3]\n",
    "\n",
    "transform = v2.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    repeat3,\n",
    "])\n",
    "\n",
    "ds_train = torchvision.datasets.Caltech101('./', transform=transform, download = True)\n",
    "ds_train = IndexSubsetDataset(ds_train, sum([list(range(len(ds_train)))[i::5] for i in range(1, 5)], []))\n",
    "\n",
    "ds_val = torchvision.datasets.Caltech101('./', transform=transform, download = True)\n",
    "ds_val = IndexSubsetDataset(ds_val, list(range(len(ds_val)))[0::5])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  ds_train,\n",
    "  batch_size=batch_size_train, shuffle=True, num_workers=0)\n",
    "\n",
    "def shearlet_transform(img):\n",
    "    return frequency_shearlet_transform(img, shearlets, patch_size)\n",
    "\n",
    "train_loader = ShearletTransformLoader(train_loader, shearlet_transform)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "  ds_val,\n",
    "  batch_size=batch_size_train, shuffle=False)\n",
    "\n",
    "val_loader = ShearletTransformLoader(val_loader, shearlet_transform)\n",
    "\n",
    "for x, y in tqdm(train_loader):\n",
    "    assert list(x.shape) == [batch_size_train, shearlets.shape[0] * 3, patch_size, patch_size], x.shape\n",
    "    break\n",
    "print('building model...')\n",
    "model = complex_resnet18(in_dim=shearlets.shape[0] * 3, complex=True, phasor=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "print('training model...')\n",
    "for epoch in range(16):\n",
    "    print('epoch', epoch)\n",
    "    train(model.to(0), optimizer, train_loader, accumulate=4)\n",
    "    gc.collect()\n",
    "    test(model, train_loader)\n",
    "    test(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(5.4802, device='cuda:0'), tensor(0., device='cuda:0'))\n",
      "(tensor(1.5708, device='cuda:0'), tensor(-1.5708, device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "# amplitude:\n",
    "amp = torch.abs(x)\n",
    "print((amp.real.max(), amp.real.min()))\n",
    "\n",
    "phase = torch.arctan(x.imag / x.real)\n",
    "\n",
    "phase = torch.nan_to_num(torch.arctan(x.imag / x.real), posinf=torch.math.pi / 2, neginf= -torch.math.pi / 2)\n",
    "\n",
    "print((phase.real.max(), phase.real.min()))\n",
    "\n",
    "def to_magnitude_phase(x):\n",
    "    \"\"\"\n",
    "    return magnitude/phase representation \n",
    "    \"\"\"\n",
    "    return torch.complex(torch.abs(x), torch.nan_to_num(torch.arctan(x.imag / x.real), posinf=torch.math.pi / 2, neginf= -torch.math.pi / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1.5,.0,.0,.0]])\n",
    "layerNorm = torch.nn.LayerNorm(4, elementwise_affine = False)\n",
    "y1 = layerNorm(x)\n",
    "mean = x.mean(-1, keepdim = True)\n",
    "var = x.var(-1, keepdim = True, unbiased=False)\n",
    "y2 = (x-mean)/torch.sqrt(var+layerNorm.eps)\n",
    "\n",
    "torch.allclose(y1, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((50,20,100))\n",
    "\n",
    "layerNorm = torch.nn.LayerNorm(x.shape[-1], elementwise_affine = True)\n",
    "y1 = layerNorm(x)\n",
    "\n",
    "mean = torch.mean(x, dim=-1, keepdim=True)\n",
    "var = torch.square(x - mean).mean(dim=-1, keepdim=True)\n",
    "y2 = ((x - mean) / torch.sqrt(var + layerNorm.eps)) * layerNorm.weight + layerNorm.bias\n",
    "\n",
    "torch.allclose(y1, y2, atol=1e-5, rtol=1e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
