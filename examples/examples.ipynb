{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shearletNN.shearlets import getcomplexshearlets2D\n",
    "from shearletNN.shearlet_utils import frequency_shearlet_transform, ShearletTransformLoader\n",
    "from shearletNN.complex_resnet import complex_resnet34\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "patch_size = 64\n",
    "image_size = 128\n",
    "\n",
    "rows, cols = image_size, image_size\n",
    "\n",
    "\n",
    "shearlets, shearletIdxs, RMS, dualFrameWeights = getcomplexshearlets2D(\trows, \n",
    "                                                                        cols, \n",
    "                                                                        1, \n",
    "                                                                        3, \n",
    "                                                                        1, \n",
    "                                                                        0.5,\n",
    "                                                                        wavelet_eff_support = image_size,\n",
    "                                                                        gaussian_eff_support = image_size\n",
    "                                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, optimizer, loader, accumulate=1):\n",
    "    model.train()\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for i, (X, y) in tqdm(enumerate(loader)):\n",
    "        out = model(X.to(0))\n",
    "        optimizer.zero_grad()\n",
    "        l = loss(out, y.to(0)) / accumulate\n",
    "        l.backward()\n",
    "        if i % accumulate == (accumulate - 1):\n",
    "            optimizer.step()\n",
    "        \n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    output = output.to(torch.device('cpu'))\n",
    "    target = target.to(torch.device('cpu'))\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.shape[0]\n",
    "\n",
    "    _, idx = output.sort(dim=1, descending=True)\n",
    "    pred = idx.narrow(1, 0, maxk).t()\n",
    "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(dim=0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "def epoch_accuracy(loader_s, student):\n",
    "    student.eval()\n",
    "\n",
    "    out_epoch_s = [accuracy(student(L.to(0)), y)[0].detach().cpu().item() for L, y in loader_s]\n",
    "\n",
    "    student.train()\n",
    "\n",
    "    return sum(out_epoch_s) / len(out_epoch_s)\n",
    "\n",
    "def test(network, test_loader):\n",
    "    network.eval().to(0)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_losses=[]\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data.to(0))\n",
    "            test_loss += torch.nn.CrossEntropyLoss()(output, target.to(0)).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1].cpu()\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "            total += target.shape[0]\n",
    "        test_loss /= total\n",
    "        test_losses.append(test_loss)\n",
    "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, total,\n",
    "        100. * correct / total))\n",
    "\n",
    "class IndexSubsetDataset:\n",
    "    def __init__(self, ds, inds):\n",
    "        self.ds = ds\n",
    "        self.inds = inds\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(len(self.inds)):\n",
    "            yield self[i]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.ds[self.inds[i]]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat3(x):\n",
    "    return x.repeat(3, 1, 1)[:3]\n",
    "\n",
    "transform = v2.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    repeat3,\n",
    "])\n",
    "\n",
    "ds_train = torchvision.datasets.Caltech101('./', transform=transform, download = True)\n",
    "ds_train = IndexSubsetDataset(ds_train, sum([list(range(len(ds_train)))[i::5] for i in range(1, 5)], []))\n",
    "\n",
    "ds_val = torchvision.datasets.Caltech101('./', transform=transform, download = True)\n",
    "ds_val = IndexSubsetDataset(ds_val, list(range(len(ds_val)))[0::5])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  ds_train,\n",
    "  batch_size=batch_size_train, shuffle=True, num_workers=0)\n",
    "\n",
    "train_loader = ShearletTransformLoader(train_loader, frequency_shearlet_transform)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "  ds_val,\n",
    "  batch_size=batch_size_train, shuffle=False)\n",
    "\n",
    "val_loader = ShearletTransformLoader(val_loader, frequency_shearlet_transform)\n",
    "\n",
    "for x, y in tqdm(train_loader):\n",
    "    assert list(x.shape) == [batch_size_train, shearlets.shape[0] * 3, patch_size, patch_size], x.shape\n",
    "    break\n",
    "print('building model...')\n",
    "model = complex_resnet34(in_dim=shearlets.shape[0] * 3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "print('training model...')\n",
    "for epoch in range(10):\n",
    "    print('epoch', epoch)\n",
    "    train(model.to(0), optimizer, train_loader, accumulate=4)\n",
    "    gc.collect()\n",
    "    test(model, train_loader)\n",
    "    test(model, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
